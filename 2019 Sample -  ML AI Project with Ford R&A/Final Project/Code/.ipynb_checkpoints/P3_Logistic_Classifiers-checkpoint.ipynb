{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Created by Joshua McCready (jmccread@umich.edu/jmccrea8@ford.com)\n",
    "## Logistic Regression for Binary Road Wheel Misalgingment Classification\n",
    "## REQUIRES UPDATE to scikit-learn=0.21.:\n",
    ">conda config --append channels conda-forge\n",
    ">conda install scikit-learn==0.21.2 \n",
    "Above commands allow for some more features in the logistic_regression class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from os import walk\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # Feeling cute might delete later\n",
    "import util.reports as rp\n",
    "from util.reports import report_feature_ranking\n",
    "from util.fspp import get_fspp\n",
    "from util.mutual import MutualInfo\n",
    "from util.reports import report_feature_ranking\n",
    "\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from hard drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"C:\\Users\\jmccrea8\\Documents\\GitHub\\ECE5831\\Data\" \n",
    "file = os.path.join(root, \"df_cat_5Hz.pkl\")\n",
    "df_cat = pd.read_pickle(file)\n",
    "file = os.path.join(root, \"df_num_5Hz.pkl\")\n",
    "df_num = pd.read_pickle(file)\n",
    "file = os.path.join(root, \"df_out_5Hz.pkl\")\n",
    "df_out = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unneeded features on the basis of feature to feature correlation and low mutual information\n",
    "|Correlation| > 0.98 against another feature: [\"Front Right Wheel Speed\", \"Front Left Wheel Speed\", \"Rear Right Wheel Speed\", \"Rear Left Wheel Speed\", \"Vehicle Yaw Rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "low mutual information: ['Total Brake Torque', 'Vehicle Lateral Acceleration', 'Accelerator Pedal Position Percent Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureNames = df_num.columns # replace with actual list of things\n",
    "toDrop = [\"Front Right Wheel Speed\", \"Front Left Wheel Speed\", \"Rear Right Wheel Speed\", \"Rear Left Wheel Speed\", \"Vehicle Yaw Rate\", 'Total Brake Torque', 'Vehicle Lateral Acceleration', 'Accelerator Pedal Position Percent Rate']\n",
    "remove = [featureNames.get_loc(label) for label in toDrop]\n",
    "allFeatures = [df_num.columns.get_loc(label) for label in featureNames]\n",
    "features = list(set(allFeatures) - set(remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and y, divide train/test, and define model + pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37255, 24)   (37255,)\n"
     ]
    }
   ],
   "source": [
    "X_full = df_num.iloc[:, features].values\n",
    "X_labels = df_num.iloc[:, features].columns\n",
    "# Create binary classifier all postive class are one kind of misalginement or another\n",
    "y_full = df_out.iloc[:, 3].values >0\n",
    "X, X_holdout, y, y_holdout = train_test_split(X_full, y_full, test_size = 0.20, random_state = 0)\n",
    "print(X_holdout.shape, \" \", y_holdout.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What settings are of interest in Logistic regression\n",
    "1. Penality - l1, l2, or elastic net\n",
    "2. tol - stoping criteria for gradient descent \n",
    "3. class_weight - Using this parameter allos for the values of y to adjust weights to class frequencies. I'm not really sure about this one\n",
    "4. solver - important because elastic net is supported by saga solver only (I think!)\n",
    "https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions \n",
    "has a really good discussion of the solver algorithms that helped me understand what to do better. Appearently, SAG (Stochastic Average Gradient) is good for larger datasets like this one, but only supports l2 regularization. SAGA is a varaint of SAG but supports l1. \n",
    "5. max_iter - Control how much time we give the algorithm to converge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = LogisticRegression(solver='saga', max_iter=500)\n",
    "\n",
    "sc = StandardScaler()\n",
    "estimators = [('normalizer', sc), ('classifier', mdl)]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "# Create Parameter Space\n",
    "C_choices = [0.01, 0.25, 0.5, 1, 5]\n",
    "penalty_choices = ['none', 'l1','l2', 'elasticnet']\n",
    "l1_ratio_choices = [0.1, 0.5, 0.9]\n",
    "\n",
    "hyperparams = {\n",
    "    'classifier__penalty': penalty_choices,\n",
    "    'classifier__C': C_choices,\n",
    "    'classifier__l1_ratio': l1_ratio_choices\n",
    "}\n",
    "\n",
    "feat_inds = np.arange(0, X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultsLst = list()\n",
    "bestPipeL = list() \n",
    "trainPerfL = list()\n",
    "validPerfL = list()\n",
    "featuresL = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup recursive feature elimination with K folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores in the cross-validation\n",
    "def report_cv(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.5f} (std: {1:.5f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# Utility function to report best score among 'elasticnet' to perform RFE - returns relevant features \n",
    "def elastic_remove_feats(validator, X, y, pipe, feat_inds, kf):\n",
    "    elasticRanks = list(np.zeros(len(validator.cv_results_['params']))-1)\n",
    "    elasticRanksInds = list(np.zeros(len(validator.cv_results_['params'])))\n",
    "    for i in range(len(validator.cv_results_['params'])):\n",
    "        params = validator.cv_results_['params'][i]\n",
    "        if (params['classifier__penalty']) == 'elasticnet':\n",
    "            elasticRanks[i] = validator.cv_results_['rank_test_score'][i]\n",
    "            elasticRanksInds[i] = i\n",
    "\n",
    "    goodRanks = list()\n",
    "    goodRanksInds = list()\n",
    "    for i in range(len(elasticRanks)):\n",
    "        if elasticRanks[i] != -1:\n",
    "            goodRanks.append(elasticRanks[i])\n",
    "            goodRanksInds.append(elasticRanksInds[i])\n",
    "\n",
    "    bestElasticInd = goodRanksInds[np.argmin(goodRanks)]\n",
    "\n",
    "    alt_pipe = pipe\n",
    "\n",
    "    i = 0\n",
    "    alt_params = {} # VERY SEXY\n",
    "    for param in validator.cv_results_['params'][bestElasticInd]:\n",
    "        ick = list(validator.cv_results_['params'][bestElasticInd].keys())[i]\n",
    "        alt_params.update({ick:validator.cv_results_['params'][bestElasticInd][param]})\n",
    "        i = i+1\n",
    "        #print(validator.cv_results_['params'][bestElasticInd][param])\n",
    "\n",
    "    for k, v in alt_params.items():\n",
    "        alt_pipe.set_params(**{k: v})\n",
    "\n",
    "    results = cross_validate(alt_pipe, X, y, cv=kf, scoring=['f1'], n_jobs=-1, return_estimator=True, return_train_score=True)\n",
    "    best_index  = results['train_f1'].argmax()\n",
    "    coefs = results['estimator'][best_index]['classifier']\n",
    "    coefs = coefs.coef_\n",
    "    feat_inds_red = list(feat_inds)\n",
    "    i = 0\n",
    "    print(coefs[0])\n",
    "    for co in coefs[0]:\n",
    "        if abs(co) <= 0.04:\n",
    "            feat_inds_red.pop(i)    \n",
    "        i = i+1\n",
    "    return np.asarray(feat_inds_red) \n",
    "    \n",
    "\n",
    "# Printer functions \n",
    "def featurePrinter(feat_inds, df_X): \n",
    "    print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "    print(\"Mutual information recursive feature elimination, using \", '%d' % len(feat_inds), \"features\")\n",
    "    #removed = np.asarray(list(set(feat_inds) - set(red_feat_inds)))\n",
    "    #print(\"Features being removed: \")\n",
    "    #print(df_X.iloc[:, removed].columns)\n",
    "    print(\"Features being used: \")\n",
    "    print(df_X.iloc[:, feat_inds].columns)\n",
    "    print(\"----------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "def resultsPrinter(results, end, start):\n",
    "    print('Elpased time:', end-start, \" seconds\")\n",
    "    print(\"----------------------------------------------------------------------------------------------\")\n",
    "    print('\\nTraining Metrics: ')\n",
    "    print('Accuracy (Avg): ', '%.2f' % results['train_accuracy'].mean())\n",
    "    print('F1 Macro (Avg): ', '%.2f' % results['train_f1'].mean())\n",
    "    print('Recall Macro (Avg): ', '%.2f' % results['train_recall'].mean())\n",
    "    print('Precision Macro (Avg): ', '%.2f' % results['train_precision'].mean())\n",
    "    print('\\nTime training (Avg): ', results['fit_time'].mean())\n",
    "    print('\\nValidation Metrics: ')\n",
    "    print('Accuracy (Avg): ', '%.2f' % results['test_accuracy'].mean())\n",
    "    print('F1 Macro (Avg): ', '%.2f' % results['test_f1'].mean())\n",
    "    print('Recall Macro (Avg): ', '%.2f' % results['test_recall'].mean())\n",
    "    print('Precision Macro (Avg): ', '%.2f' % results['test_precision'].mean(), \"\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "def removedPrinter(feat_inds, red_feat_inds, df_X): \n",
    "    removed = np.asarray(list(set(feat_inds) - set(red_feat_inds)))\n",
    "    print(\"Features being removed: \")\n",
    "    print(df_X.iloc[:, removed].columns)\n",
    "    print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to perform recursive feature reduction of k features with cross validation\n",
    "def RFE_MI(df_X, y, pipe, hyperparams, feat_inds, bestPipeLst, trainPerfLst, validPerfLst, featuresLst,  k=2, numSplt=3, prevResults=-1, verbose=1):\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    X = df_X.iloc[:, feat_inds].values # Select the features we want based on previous\n",
    "    kf = KFold(n_splits = numSplt, random_state = 0,  shuffle=True)\n",
    "\n",
    "    # Perform Model Selection  #################################################################################\n",
    "        # Cross validate with model settings ###################################################################\n",
    "    validator = GridSearchCV(pipe, param_grid=hyperparams, cv=kf, scoring='f1_macro', n_jobs=-1,verbose = 1)\n",
    "    validator.fit(X, y)\n",
    "    bestInd = validator.best_index_\n",
    "    \n",
    "    bestP = validator.best_estimator_\n",
    "    featuresLst.append(feat_inds)\n",
    "    bestPipeLst.append(bestP)\n",
    "    \n",
    "    # Use the best result to compute stuff for later ###########################################################\n",
    "    results = cross_validate(bestP, X, y, cv=kf, scoring=['accuracy', 'f1','precision','recall'], n_jobs=-1, \n",
    "                            return_estimator=True, return_train_score=True)\n",
    "    best_index  = results['train_f1'].argmax()\n",
    "    trainPerfLst.append([results['train_accuracy'][best_index], results['train_f1'][best_index],\n",
    "                         results['train_recall'][best_index], results['train_precision'][best_index]]) \n",
    "    validPerfLst.append([results['test_accuracy'][best_index], results['test_f1'][best_index],\n",
    "                         results['test_recall'][best_index], results['test_precision'][best_index]]) \n",
    "    \n",
    "   \n",
    "    \n",
    "    # Perform feature selection ###########################################################################\n",
    "    feat_inds_red = elastic_remove_feats(validator, X, y, pipe, feat_inds, kf)\n",
    "    \n",
    "    # Recursive Step  ######################################################################################### \n",
    "    if prevResults == -1:\n",
    "        prevResults = results\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    report_cv(validator.cv_results_, 5)\n",
    "    print('Elapsed time: ', end - start, ' seconds\\n')\n",
    "    \n",
    "    if verbose:\n",
    "        featurePrinter(feat_inds, df_X)\n",
    "        resultsPrinter(prevResults, results, end, start, tol)\n",
    "        removedPrinter(feat_inds, feat_inds_red, df_X)\n",
    "        \n",
    "    if len(feat_inds) <= k:\n",
    "        print(\"Stop condition reached, features less than k, returning previous results\")\n",
    "        return feat_inds, results\n",
    "    elif len(feat_inds) == len(feat_inds_red):\n",
    "        print(\"Stop condition reached, did not remove any features\")\n",
    "        return feat_inds, results\n",
    "    else: \n",
    "        return RFE_MI(df_X, y, pipe, hyperparams, feat_inds_red, bestPipeLst, trainPerfLst, validPerfLst, featuresLst, k, numSplt, results, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 60 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.5min finished\n",
      "C:\\Users\\JMCCREA8\\AppData\\Local\\Continuum\\Anaconda3-5.2.0\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1506: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07328442 -0.48379123  0.01004404  0.14423536  0.04208524 -0.19043095\n",
      "  0.09191579 -0.04483404  0.35817263 -0.4904893   5.334685   -5.4865484\n",
      " -0.0394988  -0.01633352 -0.5535682  -0.28688112  0.36610407  0.03418026\n",
      "  0.07838105 -0.33638018  0.18629956 -0.27122554 -0.32744202 -0.6721549 ]\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.68733 (std: 0.00169)\n",
      "Parameters: {'classifier__C': 1, 'classifier__l1_ratio': 0.9, 'classifier__penalty': 'l2'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.68732 (std: 0.00169)\n",
      "Parameters: {'classifier__C': 0.5, 'classifier__l1_ratio': 0.5, 'classifier__penalty': 'l2'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.68732 (std: 0.00169)\n",
      "Parameters: {'classifier__C': 1, 'classifier__l1_ratio': 0.1, 'classifier__penalty': 'l2'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.68731 (std: 0.00170)\n",
      "Parameters: {'classifier__C': 0.25, 'classifier__l1_ratio': 0.5, 'classifier__penalty': 'l2'}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.68731 (std: 0.00172)\n",
      "Parameters: {'classifier__C': 1, 'classifier__l1_ratio': 0.9, 'classifier__penalty': 'none'}\n",
      "\n",
      "Elapsed time:  94.85542559999999  seconds\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'StandardScaler' and 'LogisticRegression'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-3c68b9603e29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprevResults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfinal_feat_inds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE_MI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_inds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestPipeL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainPerfL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidPerfL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesL\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-f325ba96bbd4>\u001b[0m in \u001b[0;36mRFE_MI\u001b[1;34m(df_X, y, pipe, hyperparams, feat_inds, bestPipeLst, trainPerfLst, validPerfLst, featuresLst, k, numSplt, prevResults, verbose)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeat_inds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mRFE_MI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_inds_red\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestPipeLst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainPerfLst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidPerfLst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesLst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumSplt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-f325ba96bbd4>\u001b[0m in \u001b[0;36mRFE_MI\u001b[1;34m(df_X, y, pipe, hyperparams, feat_inds, bestPipeLst, trainPerfLst, validPerfLst, featuresLst, k, numSplt, prevResults, verbose)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_inds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;31m# Select the features we want based on previous\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumSplt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JMCCREA8\\AppData\\Local\\Continuum\\Anaconda3-5.2.0\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JMCCREA8\\AppData\\Local\\Continuum\\Anaconda3-5.2.0\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   2011\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2013\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2014\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JMCCREA8\\AppData\\Local\\Continuum\\Anaconda3-5.2.0\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n",
      "\u001b[1;32mC:\\Users\\JMCCREA8\\AppData\\Local\\Continuum\\Anaconda3-5.2.0\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1965\u001b[0m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JMCCREA8\\AppData\\Local\\Continuum\\Anaconda3-5.2.0\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     26\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     27\u001b[0m           initial=_NoValue):\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'StandardScaler' and 'LogisticRegression'"
     ]
    }
   ],
   "source": [
    "feat_inds = np.arange(0, X.shape[1], 1)\n",
    "k = 3\n",
    "prevResults = -1\n",
    "df_X = pd.DataFrame(X, columns=np.asarray(X_labels)) \n",
    "final_feat_inds, validator = RFE_MI(df_X, y, pipe, hyperparams, feat_inds, bestPipeL, trainPerfL, validPerfL, featuresL,  3, 4, -1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = list() \n",
    "holdoutPerfL = list()\n",
    "df_X_holdout = pd.DataFrame(X_holdout, columns=np.asarray(X_labels)) \n",
    "len(featuresL)\n",
    "for i in range(len(featuresL)):\n",
    "    Bpipe = bestPipeL[i]\n",
    "    feats = featuresL[i]\n",
    "    X_holdout_mod = df_X_holdout.iloc[:, feats].values # reduce to right features \n",
    "    y_pred = Bpipe.predict(X_holdout_mod)\n",
    "    y_pred_list.append(y_pred)\n",
    "    holdoutPerfL.append([accuracy_score(y_pred,y_holdout), f1_score(y_pred,y_holdout),\n",
    "                         recall_score(y_pred,y_holdout), precision_score(y_pred,y_holdout)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot K-folds performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.asarray(trainPerfL)[:,1]\n",
    "valid = np.asarray(validPerfL)[:,1]\n",
    "holdout = np.asarray(holdoutPerfL)[:,1]\n",
    "featLens = list()\n",
    "[featLens.append(len(feat)) for feat in featuresL]\n",
    "\n",
    "perfstr = 'f1_score'\n",
    "plt.figure(1)\n",
    "f1 = plt.subplot(211)\n",
    "plt.plot( featLens, train, marker='.',  color='blue',  linestyle='-', linewidth=2, label=\"K folds best training\")\n",
    "plt.plot( featLens, valid, marker='o', color='green', linewidth=2,  linestyle='dashed', label=\"K folds best validation\")\n",
    "plt.plot( featLens, holdout, marker='x', color='red', linewidth=2, linestyle=':', label=\"holdout\")\n",
    "plt.ylabel(perfstr)\n",
    "plt.xlabel('# of features')\n",
    "plt.legend()\n",
    "plt.show\n",
    "plt.axis('auto')\n",
    "plt.xticks(np.arange(min(featLens), max(featLens)+1, step=k))\n",
    "#plt.savefig('f1_naive_bayes.png')\n",
    "\n",
    "train = np.asarray(trainPerfL)[:,0]\n",
    "valid = np.asarray(validPerfL)[:,0]\n",
    "holdout = np.asarray(holdoutPerfL)[:,0]\n",
    "perfstr = 'accuracy_score'\n",
    "f1 = plt.subplot(212)\n",
    "plt.plot( featLens, train, marker='.',  color='blue',  linestyle='-', linewidth=2, label=\"K folds best training\")\n",
    "plt.plot( featLens, valid, marker='o', color='green', linewidth=2,  linestyle='dashed', label=\"K folds best validation\")\n",
    "plt.plot( featLens, holdout, marker='x', color='red', linewidth=2, linestyle=':', label=\"holdout\")\n",
    "plt.ylabel(perfstr)\n",
    "plt.xlabel('# of features')\n",
    "#plt.legend()\n",
    "plt.show\n",
    "plt.axis('auto')\n",
    "plt.xticks(np.arange(min(featLens), max(featLens)+1, step=k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print performance in the holdout dataset against the best model (with 9 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = featLens.index(9) # seems to satisfy the heuristic of low number of features, high f1 and accuracy \n",
    "Bpipe = bestPipeL[best]\n",
    "feats = featuresL[best]\n",
    "y_pred = y_pred_list[best]\n",
    "print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "print('Holdout Test Metrics: ')\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print('Accuracy: ', '%.2f' % accuracy_score(y_pred,y_holdout))\n",
    "print('F1 Score: ', '%.2f' % f1_score(y_pred,y_holdout))\n",
    "print('Recall: ', '%.2f' % recall_score(y_pred,y_holdout))\n",
    "print('Precision: ', '%.2f' % precision_score(y_pred,y_holdout))\n",
    "print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_pred)\n",
    "cm_normal = cm/len(y_pred)*100\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(cm_normal,  cmap=\"YlGnBu\", annot=True,annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\".\\results\\final_naive_bayes\" \n",
    "pickle.dump(Bpipe, open(filename, 'wb'))\n",
    "#NB_best = pickle.load(open(filename, 'rb'))\n",
    "#type(NB_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
