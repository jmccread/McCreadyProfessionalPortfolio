{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Created by Luis Alejandro (alejand@umich.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Feature Sensitivity to Posterior Probability (FSPP)\n",
    "Computes a wrapper feature ranking especifically designed for MLP neural networks using the algorithm proposed by:\n",
    "\n",
    "https://ieeexplore.ieee.org/abstract/document/5282531\n",
    "\n",
    "and briefly compares to Mutual Information (MI) raking criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from util.fspp import get_fspp\n",
    "from util.mutual import MutualInfo\n",
    "from util.reports import report_feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_breast_cancer()\n",
    "print(dataset.feature_names, end=\"\\n\")\n",
    "print(dataset.target_names)\n",
    "predictors = dataset.data\n",
    "responses = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits into training/test sets\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors,responses,test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time training (Avg):  0.2455455780029297\n",
      "\n",
      "Training Metrics: \n",
      "Accuracy (Avg):  0.99\n",
      "\n",
      "Validation Metrics: \n",
      "Accuracy (Avg):  0.97\n",
      "\n",
      "Test Metrics: \n",
      "Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "# Defines model\n",
    "sc = StandardScaler()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(30))\n",
    "estimators = [('normalizer', sc), ('classifier', clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "results = cross_validate(pipe,X,y,cv = 5,scoring = ['accuracy'], n_jobs=-1,\n",
    "                         return_estimator=True, return_train_score=True)\n",
    "print('\\nTime training (Avg): ', results['fit_time'].mean())\n",
    "print('\\nTraining Metrics: ')\n",
    "print('Accuracy (Avg): ', '%.2f' % results['train_accuracy'].mean())\n",
    "print('\\nValidation Metrics: ')\n",
    "print('Accuracy (Avg): ', '%.2f' % results['test_accuracy'].mean())\n",
    "\n",
    "best_pipe = results['estimator'][results['test_accuracy'].argmin()]\n",
    "y_pred = best_pipe.predict(X_holdout)\n",
    "print('\\nTest Metrics: ')\n",
    "print('Accuracy: ', '%.2f' % accuracy_score(y_pred,y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranked 1 is (worst concavity) with value 0.060510\n",
      "Feature ranked 2 is (worst texture) with value 0.051955\n",
      "Feature ranked 3 is (worst symmetry) with value 0.042880\n",
      "Feature ranked 4 is (mean radius) with value 0.040917\n",
      "Feature ranked 5 is (mean texture) with value 0.039978\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is (mean symmetry) with value 0.009587\n",
      "Feature ranked 27 is (worst compactness) with value 0.008778\n",
      "Feature ranked 28 is (concave points error) with value 0.008631\n",
      "Feature ranked 29 is (worst fractal dimension) with value 0.007146\n",
      "Feature ranked 30 is (smoothness error) with value 0.006954\n"
     ]
    }
   ],
   "source": [
    "rank = get_fspp(best_pipe,X)\n",
    "report_feature_ranking(rank,dataset.feature_names,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallel version\n",
      "Feature ranked 1 is (worst concave points) with value 0.735890\n",
      "Feature ranked 2 is (mean concave points) with value 0.708632\n",
      "Feature ranked 3 is (worst perimeter) with value 0.708524\n",
      "Feature ranked 4 is (worst area) with value 0.664548\n",
      "Feature ranked 5 is (worst radius) with value 0.661705\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is (mean fractal dimension) with value 0.146247\n",
      "Feature ranked 27 is (symmetry error) with value 0.143084\n",
      "Feature ranked 28 is (fractal dimension error) with value 0.141861\n",
      "Feature ranked 29 is (smoothness error) with value 0.137136\n",
      "Feature ranked 30 is (texture error) with value 0.125159\n"
     ]
    }
   ],
   "source": [
    "mi = MutualInfo(X,y,100,n_jobs=4)\n",
    "rank = mi.compute()\n",
    "report_feature_ranking(rank,dataset.feature_names,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning]",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
